{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVaWVR1iL4Xg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random as rn\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import SVG\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import gc\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.python.keras.utils.vis_utils import model_to_dot\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50,preprocess_input\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "from tensorflow.keras.applications import DenseNet201\n",
        "\n",
        "from tensorflow.keras import  layers, models\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split,KFold, cross_val_score, GridSearchCV\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, save_img\n",
        "from tensorflow.keras.layers import Dense, Flatten, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization, Dropout, Conv2D, MaxPool2D, Activation\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn import metrics\n",
        "#from sklearn.metrics import plot_confusion_matrix\n",
        "from tensorflow.keras.utils import plot_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JW8P_Zl3MCOz",
        "outputId": "a73ff936-3880-4991-c300-926756bfbae6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# Now you can use functions from the glob module\n",
        "\n",
        "# Rest of your code\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "lung_cancer_dataset_path = r\"/content/drive/MyDrive/Sem4_Project /Lung Cancer/Dataset\"\n",
        "imagePatches = glob.glob(os.path.join(lung_cancer_dataset_path, '**', '*.*'), recursive=True)\n",
        "\n",
        "x = []\n",
        "y = []\n",
        "\n",
        "for img_path in imagePatches:\n",
        "\n",
        "    # Check if the file is an image (jpg, png, etc.)\n",
        "    _, file_extension = os.path.splitext(img_path)\n",
        "    if file_extension.lower() in {'.png', '.jpg', '.jpeg'}:\n",
        "        # Use PIL to open the image\n",
        "        try:\n",
        "            img = Image.open(img_path)\n",
        "            img = img.resize((224, 224))\n",
        "\n",
        "            # Convert RGBA or other modes to RGB\n",
        "            if img.mode != 'RGB':\n",
        "                img = img.convert('RGB')\n",
        "\n",
        "            im = np.array(img) / 255.0  # Normalize pixel values\n",
        "            x.append(im)\n",
        "\n",
        "            # Extract the class label from the subdirectory name\n",
        "            class_label = os.path.basename(os.path.dirname(img_path))\n",
        "\n",
        "            if 'benign' in class_label:\n",
        "                y.append(0)\n",
        "            elif 'malignant' in class_label:\n",
        "                y.append(1)\n",
        "            elif 'normal' in class_label:\n",
        "                y.append(2)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {img_path}: {str(e)}\")\n",
        "\n",
        "x = np.array(x)\n",
        "y = np.array(y)\n"
      ],
      "metadata": {
        "id": "WMNPoe_8MFMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of images:\", len(imagePatches))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNhTWO65MH31",
        "outputId": "ddc8a1bb-8f44-4682-c7a4-25e596d00dc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images: 2074\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state=101, stratify=y)\n",
        "\n",
        "# One-hot encode the labels for training and validation sets\n",
        "y_train = to_categorical(y_train, num_classes=3)\n",
        "y_valid = to_categorical(y_valid, num_classes=3)\n",
        "\n",
        "# Delete the original x and y to free up memory\n",
        "del x, y\n"
      ],
      "metadata": {
        "id": "qgNAaJA5MK3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# config the session\n",
        "import tensorflow as tf\n",
        "\n",
        "# Set the seed for hash based operations in python\n",
        "os.environ['PYTHONHASHSEED'] = '0'\n",
        "\n",
        "# Set the numpy seed\n",
        "np.random.seed(111)\n",
        "\n",
        "# Set the random seed in tensorflow at graph level\n",
        "tf.random.set_seed(111)\n",
        "from random import seed\n",
        "seed(111)"
      ],
      "metadata": {
        "id": "oFaZ-xvtMP0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import layers, Model, backend\n",
        "\n",
        "channel_axis = -1  # color channels are expected to be the last dimension of the input data\n",
        "\n",
        "def conv_block(input_tensor, filters, kernel_size, strides=(1, 1), name=None):\n",
        "    \"\"\"Convolution Block with BatchNormalization and ReLU activation.\"\"\"\n",
        "    if name is not None:\n",
        "        conv_name = name + '_conv'\n",
        "        bn_name = name + '_bn'\n",
        "        act_name = name + '_act'\n",
        "    else:\n",
        "        conv_name = None\n",
        "        bn_name = None\n",
        "        act_name = None\n",
        "\n",
        "    x = layers.Conv2D(filters, kernel_size,\n",
        "                      strides=strides,\n",
        "                      padding='same',\n",
        "                      use_bias=False,\n",
        "                      name=conv_name)(input_tensor)\n",
        "    x = layers.BatchNormalization(axis=channel_axis, name=bn_name)(x)\n",
        "    x = layers.Activation('relu', name=act_name)(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def residual_block(input_tensor, filters, kernel_size, strides=(1, 1), adjust_dimensions=False, block_name=None):\n",
        "    \"\"\"A Residual Block with optional dimension adjustment.\"\"\"\n",
        "    # Path to adjust dimensions if needed\n",
        "    shortcut = input_tensor\n",
        "    if adjust_dimensions:\n",
        "        shortcut = layers.Conv2D(filters, (1, 1), strides=strides, padding='same', use_bias=False)(shortcut)\n",
        "        shortcut = layers.BatchNormalization(axis=channel_axis)(shortcut)\n",
        "\n",
        "    # Main path\n",
        "    x = conv_block(input_tensor, filters, kernel_size, strides=strides, name=f'{block_name}_conv1')\n",
        "    x = conv_block(x, filters, kernel_size, strides=(1, 1), name=f'{block_name}_conv2')\n",
        "\n",
        "    # Adding back the shortcut path\n",
        "    x = layers.add([x, shortcut])\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def build_model():\n",
        "    img_input = layers.Input(shape=(224, 224, 3))\n",
        "\n",
        "    # Initial Conv Block\n",
        "    x = conv_block(img_input, 32, (3, 3), name='block1')\n",
        "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same', name='block1_pool')(x)\n",
        "\n",
        "    # First Residual Block\n",
        "    x = residual_block(x, 32, (3, 3), block_name='block2')\n",
        "\n",
        "    # Further blocks can be added in a similar fashion\n",
        "    # Notice we need to adjust dimensions when increasing the number of filters\n",
        "    x = residual_block(x, 64, (3, 3), adjust_dimensions=True, strides=(2, 2), block_name='block3')\n",
        "\n",
        "    # Continue building your model\n",
        "    # For simplicity, adding one more block and then going to dense layers\n",
        "    x = residual_block(x, 128, (3, 3), adjust_dimensions=True, strides=(2, 2), block_name='block4')\n",
        "    x = layers.MaxPooling2D((3, 3), strides=(3, 3), padding='same', name='final_pool')(x)\n",
        "\n",
        "    # Final Dense Layers\n",
        "    x = layers.Flatten(name='flatten')(x)\n",
        "    x = layers.Dense(512, activation='relu', name='fc1')(x)\n",
        "    x = layers.Dense(3, activation='softmax', name='predictions')(x)\n",
        "\n",
        "    model = Model(inputs=img_input, outputs=x, name='model_with_skip_connections')\n",
        "    return model\n",
        "\n",
        "model = build_model()\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CizTdOXHMUWE",
        "outputId": "63835fbe-0512-4cf6-af87-598188dc62d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_with_skip_connections\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " block1_conv (Conv2D)        (None, 224, 224, 32)         864       ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " block1_bn (BatchNormalizat  (None, 224, 224, 32)         128       ['block1_conv[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " block1_act (Activation)     (None, 224, 224, 32)         0         ['block1_bn[0][0]']           \n",
            "                                                                                                  \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 32)         0         ['block1_act[0][0]']          \n",
            "                                                                                                  \n",
            " block2_conv1_conv (Conv2D)  (None, 112, 112, 32)         9216      ['block1_pool[0][0]']         \n",
            "                                                                                                  \n",
            " block2_conv1_bn (BatchNorm  (None, 112, 112, 32)         128       ['block2_conv1_conv[0][0]']   \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block2_conv1_act (Activati  (None, 112, 112, 32)         0         ['block2_conv1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block2_conv2_conv (Conv2D)  (None, 112, 112, 32)         9216      ['block2_conv1_act[0][0]']    \n",
            "                                                                                                  \n",
            " block2_conv2_bn (BatchNorm  (None, 112, 112, 32)         128       ['block2_conv2_conv[0][0]']   \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block2_conv2_act (Activati  (None, 112, 112, 32)         0         ['block2_conv2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " add (Add)                   (None, 112, 112, 32)         0         ['block2_conv2_act[0][0]',    \n",
            "                                                                     'block1_pool[0][0]']         \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 112, 112, 32)         0         ['add[0][0]']                 \n",
            "                                                                                                  \n",
            " block3_conv1_conv (Conv2D)  (None, 56, 56, 64)           18432     ['activation[0][0]']          \n",
            "                                                                                                  \n",
            " block3_conv1_bn (BatchNorm  (None, 56, 56, 64)           256       ['block3_conv1_conv[0][0]']   \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block3_conv1_act (Activati  (None, 56, 56, 64)           0         ['block3_conv1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block3_conv2_conv (Conv2D)  (None, 56, 56, 64)           36864     ['block3_conv1_act[0][0]']    \n",
            "                                                                                                  \n",
            " block3_conv2_bn (BatchNorm  (None, 56, 56, 64)           256       ['block3_conv2_conv[0][0]']   \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 56, 56, 64)           2048      ['activation[0][0]']          \n",
            "                                                                                                  \n",
            " block3_conv2_act (Activati  (None, 56, 56, 64)           0         ['block3_conv2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 56, 56, 64)           256       ['conv2d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_1 (Add)                 (None, 56, 56, 64)           0         ['block3_conv2_act[0][0]',    \n",
            "                                                                     'batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " activation_1 (Activation)   (None, 56, 56, 64)           0         ['add_1[0][0]']               \n",
            "                                                                                                  \n",
            " block4_conv1_conv (Conv2D)  (None, 28, 28, 128)          73728     ['activation_1[0][0]']        \n",
            "                                                                                                  \n",
            " block4_conv1_bn (BatchNorm  (None, 28, 28, 128)          512       ['block4_conv1_conv[0][0]']   \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block4_conv1_act (Activati  (None, 28, 28, 128)          0         ['block4_conv1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block4_conv2_conv (Conv2D)  (None, 28, 28, 128)          147456    ['block4_conv1_act[0][0]']    \n",
            "                                                                                                  \n",
            " block4_conv2_bn (BatchNorm  (None, 28, 28, 128)          512       ['block4_conv2_conv[0][0]']   \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 28, 28, 128)          8192      ['activation_1[0][0]']        \n",
            "                                                                                                  \n",
            " block4_conv2_act (Activati  (None, 28, 28, 128)          0         ['block4_conv2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 28, 28, 128)          512       ['conv2d_1[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add_2 (Add)                 (None, 28, 28, 128)          0         ['block4_conv2_act[0][0]',    \n",
            "                                                                     'batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " activation_2 (Activation)   (None, 28, 28, 128)          0         ['add_2[0][0]']               \n",
            "                                                                                                  \n",
            " final_pool (MaxPooling2D)   (None, 10, 10, 128)          0         ['activation_2[0][0]']        \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 12800)                0         ['final_pool[0][0]']          \n",
            "                                                                                                  \n",
            " fc1 (Dense)                 (None, 512)                  6554112   ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            " predictions (Dense)         (None, 3)                    1539      ['fc1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 6864355 (26.19 MB)\n",
            "Trainable params: 6863011 (26.18 MB)\n",
            "Non-trainable params: 1344 (5.25 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LEARN_RATE = 1e-4\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "model.compile(optimizer = Adam(lr = LEARN_RATE), loss = 'categorical_crossentropy',\n",
        "                           metrics = ['categorical_accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIws05HGMxN1",
        "outputId": "6deb8f13-46da-4be3-cf30-d6e5c5721f6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
        "weight_path=\"{}.best_only.hdf5\".format('save')\n",
        "\n",
        "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1,\n",
        "                             save_best_only=True, mode='min', save_weights_only = True)\n",
        "\n",
        "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8,\n",
        "                              patience=5, verbose=1, mode='auto',\n",
        "                              epsilon=0.0001, cooldown=5, min_lr=0.0001)\n",
        "early = EarlyStopping(monitor=\"val_loss\",\n",
        "                      mode=\"min\",\n",
        "                      patience=40) # probably needs to be more patient, but kaggle time is limited\n",
        "callbacks_list = [checkpoint, early,reduceLROnPlat]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FztLT6yAM2Il",
        "outputId": "cd112697-adc2-4108-f6c7-f1fb8d18c266"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "history = model.fit(x_train,y_train,batch_size = 16,\n",
        "                    epochs = 100, verbose=1,  validation_split=0.2, callbacks=callbacks_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kmer3fiHM4MF",
        "outputId": "2884d3ba-5422-4c76-e731-6f4216720479"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 6.6356 - categorical_accuracy: 0.6843\n",
            "Epoch 1: val_loss improved from inf to 16.96394, saving model to save.best_only.hdf5\n",
            "83/83 [==============================] - 16s 78ms/step - loss: 6.6356 - categorical_accuracy: 0.6843 - val_loss: 16.9639 - val_categorical_accuracy: 0.6777 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.6410 - categorical_accuracy: 0.8018\n",
            "Epoch 2: val_loss did not improve from 16.96394\n",
            "83/83 [==============================] - 4s 51ms/step - loss: 0.6410 - categorical_accuracy: 0.8018 - val_loss: 39.7174 - val_categorical_accuracy: 0.6777 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "82/83 [============================>.] - ETA: 0s - loss: 0.2253 - categorical_accuracy: 0.9139\n",
            "Epoch 3: val_loss did not improve from 16.96394\n",
            "83/83 [==============================] - 4s 48ms/step - loss: 0.2276 - categorical_accuracy: 0.9126 - val_loss: 34.3761 - val_categorical_accuracy: 0.6777 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "82/83 [============================>.] - ETA: 0s - loss: 0.4593 - categorical_accuracy: 0.8925\n",
            "Epoch 4: val_loss improved from 16.96394 to 1.56293, saving model to save.best_only.hdf5\n",
            "83/83 [==============================] - 4s 49ms/step - loss: 0.4589 - categorical_accuracy: 0.8922 - val_loss: 1.5629 - val_categorical_accuracy: 0.6777 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.5273 - categorical_accuracy: 0.8892\n",
            "Epoch 5: val_loss did not improve from 1.56293\n",
            "83/83 [==============================] - 4s 50ms/step - loss: 0.5273 - categorical_accuracy: 0.8892 - val_loss: 1.8463 - val_categorical_accuracy: 0.6867 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "82/83 [============================>.] - ETA: 0s - loss: 0.1206 - categorical_accuracy: 0.9642\n",
            "Epoch 6: val_loss improved from 1.56293 to 0.69892, saving model to save.best_only.hdf5\n",
            "83/83 [==============================] - 4s 50ms/step - loss: 0.1195 - categorical_accuracy: 0.9646 - val_loss: 0.6989 - val_categorical_accuracy: 0.7681 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.1032 - categorical_accuracy: 0.9699\n",
            "Epoch 7: val_loss improved from 0.69892 to 0.40054, saving model to save.best_only.hdf5\n",
            "83/83 [==============================] - 4s 49ms/step - loss: 0.1032 - categorical_accuracy: 0.9699 - val_loss: 0.4005 - val_categorical_accuracy: 0.8765 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0581 - categorical_accuracy: 0.9849\n",
            "Epoch 8: val_loss improved from 0.40054 to 0.17834, saving model to save.best_only.hdf5\n",
            "83/83 [==============================] - 4s 51ms/step - loss: 0.0581 - categorical_accuracy: 0.9849 - val_loss: 0.1783 - val_categorical_accuracy: 0.9729 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "82/83 [============================>.] - ETA: 0s - loss: 0.0456 - categorical_accuracy: 0.9794\n",
            "Epoch 9: val_loss did not improve from 0.17834\n",
            "83/83 [==============================] - 4s 50ms/step - loss: 0.0451 - categorical_accuracy: 0.9797 - val_loss: 0.3951 - val_categorical_accuracy: 0.8916 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0815 - categorical_accuracy: 0.9804\n",
            "Epoch 10: val_loss did not improve from 0.17834\n",
            "83/83 [==============================] - 4s 48ms/step - loss: 0.0815 - categorical_accuracy: 0.9804 - val_loss: 0.3148 - val_categorical_accuracy: 0.9518 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.1381 - categorical_accuracy: 0.9631\n",
            "Epoch 11: val_loss did not improve from 0.17834\n",
            "83/83 [==============================] - 4s 53ms/step - loss: 0.1381 - categorical_accuracy: 0.9631 - val_loss: 3.8726 - val_categorical_accuracy: 0.5452 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0535 - categorical_accuracy: 0.9819\n",
            "Epoch 12: val_loss did not improve from 0.17834\n",
            "83/83 [==============================] - 4s 50ms/step - loss: 0.0535 - categorical_accuracy: 0.9819 - val_loss: 0.2656 - val_categorical_accuracy: 0.9639 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "82/83 [============================>.] - ETA: 0s - loss: 0.0249 - categorical_accuracy: 0.9916\n",
            "Epoch 13: val_loss did not improve from 0.17834\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
            "83/83 [==============================] - 4s 48ms/step - loss: 0.0247 - categorical_accuracy: 0.9917 - val_loss: 0.7018 - val_categorical_accuracy: 0.8705 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "82/83 [============================>.] - ETA: 0s - loss: 0.0158 - categorical_accuracy: 0.9954\n",
            "Epoch 14: val_loss did not improve from 0.17834\n",
            "83/83 [==============================] - 4s 49ms/step - loss: 0.0157 - categorical_accuracy: 0.9955 - val_loss: 0.3541 - val_categorical_accuracy: 0.9639 - lr: 8.0000e-04\n",
            "Epoch 15/100\n",
            "82/83 [============================>.] - ETA: 0s - loss: 0.0104 - categorical_accuracy: 0.9970\n",
            "Epoch 15: val_loss did not improve from 0.17834\n",
            "83/83 [==============================] - 4s 51ms/step - loss: 0.0103 - categorical_accuracy: 0.9970 - val_loss: 0.2800 - val_categorical_accuracy: 0.9669 - lr: 8.0000e-04\n",
            "Epoch 16/100\n",
            "82/83 [============================>.] - ETA: 0s - loss: 0.0181 - categorical_accuracy: 0.9962\n",
            "Epoch 16: val_loss did not improve from 0.17834\n",
            "83/83 [==============================] - 4s 49ms/step - loss: 0.0179 - categorical_accuracy: 0.9962 - val_loss: 0.2703 - val_categorical_accuracy: 0.9759 - lr: 8.0000e-04\n",
            "Epoch 17/100\n",
            "82/83 [============================>.] - ETA: 0s - loss: 0.0049 - categorical_accuracy: 0.9992\n",
            "Epoch 17: val_loss did not improve from 0.17834\n",
            "83/83 [==============================] - 4s 49ms/step - loss: 0.0049 - categorical_accuracy: 0.9992 - val_loss: 0.2946 - val_categorical_accuracy: 0.9729 - lr: 8.0000e-04\n",
            "Epoch 18/100\n",
            "82/83 [============================>.] - ETA: 0s - loss: 0.0283 - categorical_accuracy: 0.9916\n",
            "Epoch 18: val_loss did not improve from 0.17834\n",
            "83/83 [==============================] - 4s 51ms/step - loss: 0.0280 - categorical_accuracy: 0.9917 - val_loss: 0.2702 - val_categorical_accuracy: 0.9729 - lr: 8.0000e-04\n",
            "Epoch 19/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0092 - categorical_accuracy: 0.9985\n",
            "Epoch 19: val_loss did not improve from 0.17834\n",
            "83/83 [==============================] - 4s 49ms/step - loss: 0.0092 - categorical_accuracy: 0.9985 - val_loss: 0.2862 - val_categorical_accuracy: 0.9699 - lr: 8.0000e-04\n",
            "Epoch 20/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0141 - categorical_accuracy: 0.9947\n",
            "Epoch 20: val_loss did not improve from 0.17834\n",
            "83/83 [==============================] - 4s 49ms/step - loss: 0.0141 - categorical_accuracy: 0.9947 - val_loss: 0.2857 - val_categorical_accuracy: 0.9639 - lr: 8.0000e-04\n",
            "Epoch 21/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0078 - categorical_accuracy: 0.9985\n",
            "Epoch 21: val_loss did not improve from 0.17834\n",
            "83/83 [==============================] - 4s 51ms/step - loss: 0.0078 - categorical_accuracy: 0.9985 - val_loss: 0.3180 - val_categorical_accuracy: 0.9729 - lr: 8.0000e-04\n",
            "Epoch 22/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0022 - categorical_accuracy: 0.9985\n",
            "Epoch 22: val_loss did not improve from 0.17834\n",
            "\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
            "83/83 [==============================] - 4s 50ms/step - loss: 0.0022 - categorical_accuracy: 0.9985 - val_loss: 0.3156 - val_categorical_accuracy: 0.9669 - lr: 8.0000e-04\n",
            "Epoch 23/100\n",
            "82/83 [============================>.] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 1.0000\n",
            "Epoch 23: val_loss did not improve from 0.17834\n",
            "83/83 [==============================] - 4s 49ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 0.2914 - val_categorical_accuracy: 0.9699 - lr: 6.4000e-04\n",
            "Epoch 24/100\n",
            "82/83 [============================>.] - ETA: 0s - loss: 0.4250 - categorical_accuracy: 0.9764\n",
            "Epoch 24: val_loss did not improve from 0.17834\n",
            "83/83 [==============================] - 4s 51ms/step - loss: 0.4394 - categorical_accuracy: 0.9751 - val_loss: 3.6189 - val_categorical_accuracy: 0.8705 - lr: 6.4000e-04\n",
            "Epoch 25/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.1730 - categorical_accuracy: 0.9616\n",
            "Epoch 25: val_loss did not improve from 0.17834\n",
            "83/83 [==============================] - 4s 51ms/step - loss: 0.1730 - categorical_accuracy: 0.9616 - val_loss: 0.3961 - val_categorical_accuracy: 0.9488 - lr: 6.4000e-04\n",
            "Epoch 26/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0355 - categorical_accuracy: 0.9902\n",
            "Epoch 26: val_loss did not improve from 0.17834\n",
            "83/83 [==============================] - 4s 49ms/step - loss: 0.0355 - categorical_accuracy: 0.9902 - val_loss: 0.2798 - val_categorical_accuracy: 0.9608 - lr: 6.4000e-04\n",
            "Epoch 27/100\n",
            "82/83 [============================>.] - ETA: 0s - loss: 0.0089 - categorical_accuracy: 0.9985\n",
            "Epoch 27: val_loss did not improve from 0.17834\n",
            "83/83 [==============================] - 4s 50ms/step - loss: 0.0088 - categorical_accuracy: 0.9985 - val_loss: 0.1969 - val_categorical_accuracy: 0.9789 - lr: 6.4000e-04\n",
            "Epoch 28/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0084 - categorical_accuracy: 0.9985\n",
            "Epoch 28: val_loss did not improve from 0.17834\n",
            "83/83 [==============================] - 4s 51ms/step - loss: 0.0084 - categorical_accuracy: 0.9985 - val_loss: 0.2654 - val_categorical_accuracy: 0.9669 - lr: 6.4000e-04\n",
            "Epoch 29/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0149 - categorical_accuracy: 0.9940\n",
            "Epoch 29: val_loss did not improve from 0.17834\n",
            "83/83 [==============================] - 4s 49ms/step - loss: 0.0149 - categorical_accuracy: 0.9940 - val_loss: 0.2832 - val_categorical_accuracy: 0.9639 - lr: 6.4000e-04\n",
            "Epoch 30/100\n",
            "82/83 [============================>.] - ETA: 0s - loss: 0.0052 - categorical_accuracy: 0.9977\n",
            "Epoch 30: val_loss did not improve from 0.17834\n",
            "83/83 [==============================] - 4s 50ms/step - loss: 0.0051 - categorical_accuracy: 0.9977 - val_loss: 0.1969 - val_categorical_accuracy: 0.9759 - lr: 6.4000e-04\n",
            "Epoch 31/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0067 - categorical_accuracy: 0.9985\n",
            "Epoch 31: val_loss did not improve from 0.17834\n",
            "\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
            "83/83 [==============================] - 4s 52ms/step - loss: 0.0067 - categorical_accuracy: 0.9985 - val_loss: 0.3506 - val_categorical_accuracy: 0.9669 - lr: 6.4000e-04\n",
            "Epoch 32/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0087 - categorical_accuracy: 0.9985\n",
            "Epoch 32: val_loss did not improve from 0.17834\n",
            "83/83 [==============================] - 4s 50ms/step - loss: 0.0087 - categorical_accuracy: 0.9985 - val_loss: 0.2732 - val_categorical_accuracy: 0.9699 - lr: 5.1200e-04\n",
            "Epoch 33/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0022 - categorical_accuracy: 0.9992\n",
            "Epoch 33: val_loss did not improve from 0.17834\n",
            "83/83 [==============================] - 4s 50ms/step - loss: 0.0022 - categorical_accuracy: 0.9992 - val_loss: 0.2654 - val_categorical_accuracy: 0.9729 - lr: 5.1200e-04\n",
            "Epoch 34/100\n",
            "82/83 [============================>.] - ETA: 0s - loss: 0.0065 - categorical_accuracy: 0.9985\n",
            "Epoch 34: val_loss did not improve from 0.17834\n",
            "83/83 [==============================] - 4s 53ms/step - loss: 0.0064 - categorical_accuracy: 0.9985 - val_loss: 0.2618 - val_categorical_accuracy: 0.9759 - lr: 5.1200e-04\n",
            "Epoch 35/100\n",
            "82/83 [============================>.] - ETA: 0s - loss: 8.2957e-04 - categorical_accuracy: 1.0000\n",
            "Epoch 35: val_loss did not improve from 0.17834\n",
            "83/83 [==============================] - 4s 50ms/step - loss: 8.2154e-04 - categorical_accuracy: 1.0000 - val_loss: 0.2650 - val_categorical_accuracy: 0.9789 - lr: 5.1200e-04\n",
            "Epoch 36/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0035 - categorical_accuracy: 0.9992\n",
            "Epoch 36: val_loss did not improve from 0.17834\n",
            "83/83 [==============================] - 4s 50ms/step - loss: 0.0035 - categorical_accuracy: 0.9992 - val_loss: 0.2848 - val_categorical_accuracy: 0.9669 - lr: 5.1200e-04\n",
            "Epoch 37/100\n",
            "82/83 [============================>.] - ETA: 0s - loss: 0.0012 - categorical_accuracy: 1.0000\n",
            "Epoch 37: val_loss did not improve from 0.17834\n",
            "83/83 [==============================] - 4s 52ms/step - loss: 0.0012 - categorical_accuracy: 1.0000 - val_loss: 0.2817 - val_categorical_accuracy: 0.9729 - lr: 5.1200e-04\n",
            "Epoch 38/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 4.9892e-04 - categorical_accuracy: 1.0000\n",
            "Epoch 38: val_loss did not improve from 0.17834\n",
            "83/83 [==============================] - 4s 50ms/step - loss: 4.9892e-04 - categorical_accuracy: 1.0000 - val_loss: 0.2848 - val_categorical_accuracy: 0.9759 - lr: 5.1200e-04\n",
            "Epoch 39/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 5.3544e-04 - categorical_accuracy: 1.0000\n",
            "Epoch 39: val_loss did not improve from 0.17834\n",
            "83/83 [==============================] - 4s 50ms/step - loss: 5.3544e-04 - categorical_accuracy: 1.0000 - val_loss: 0.2700 - val_categorical_accuracy: 0.9759 - lr: 5.1200e-04\n",
            "Epoch 40/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 4.0684e-04 - categorical_accuracy: 1.0000\n",
            "Epoch 40: val_loss did not improve from 0.17834\n",
            "\n",
            "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
            "83/83 [==============================] - 4s 51ms/step - loss: 4.0684e-04 - categorical_accuracy: 1.0000 - val_loss: 0.2731 - val_categorical_accuracy: 0.9759 - lr: 5.1200e-04\n",
            "Epoch 41/100\n",
            "82/83 [============================>.] - ETA: 0s - loss: 3.4648e-04 - categorical_accuracy: 1.0000\n",
            "Epoch 41: val_loss did not improve from 0.17834\n",
            "83/83 [==============================] - 4s 50ms/step - loss: 3.4350e-04 - categorical_accuracy: 1.0000 - val_loss: 0.2731 - val_categorical_accuracy: 0.9759 - lr: 4.0960e-04\n",
            "Epoch 42/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 3.4074e-04 - categorical_accuracy: 1.0000\n",
            "Epoch 42: val_loss did not improve from 0.17834\n",
            "83/83 [==============================] - 4s 50ms/step - loss: 3.4074e-04 - categorical_accuracy: 1.0000 - val_loss: 0.2758 - val_categorical_accuracy: 0.9759 - lr: 4.0960e-04\n",
            "Epoch 43/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 2.6394e-04 - categorical_accuracy: 1.0000\n",
            "Epoch 43: val_loss did not improve from 0.17834\n",
            "83/83 [==============================] - 4s 51ms/step - loss: 2.6394e-04 - categorical_accuracy: 1.0000 - val_loss: 0.2762 - val_categorical_accuracy: 0.9759 - lr: 4.0960e-04\n",
            "Epoch 44/100\n",
            "82/83 [============================>.] - ETA: 0s - loss: 2.4806e-04 - categorical_accuracy: 1.0000\n",
            "Epoch 44: val_loss did not improve from 0.17834\n",
            "83/83 [==============================] - 4s 51ms/step - loss: 2.4608e-04 - categorical_accuracy: 1.0000 - val_loss: 0.2761 - val_categorical_accuracy: 0.9759 - lr: 4.0960e-04\n",
            "Epoch 45/100\n",
            "82/83 [============================>.] - ETA: 0s - loss: 2.3741e-04 - categorical_accuracy: 1.0000\n",
            "Epoch 45: val_loss did not improve from 0.17834\n",
            "83/83 [==============================] - 4s 50ms/step - loss: 2.3535e-04 - categorical_accuracy: 1.0000 - val_loss: 0.2771 - val_categorical_accuracy: 0.9759 - lr: 4.0960e-04\n",
            "Epoch 46/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 1.8916e-04 - categorical_accuracy: 1.0000\n",
            "Epoch 46: val_loss did not improve from 0.17834\n",
            "83/83 [==============================] - 4s 51ms/step - loss: 1.8916e-04 - categorical_accuracy: 1.0000 - val_loss: 0.2768 - val_categorical_accuracy: 0.9759 - lr: 4.0960e-04\n",
            "Epoch 47/100\n",
            "82/83 [============================>.] - ETA: 0s - loss: 4.8154e-04 - categorical_accuracy: 1.0000\n",
            "Epoch 47: val_loss did not improve from 0.17834\n",
            "83/83 [==============================] - 4s 51ms/step - loss: 4.7812e-04 - categorical_accuracy: 1.0000 - val_loss: 0.2955 - val_categorical_accuracy: 0.9729 - lr: 4.0960e-04\n",
            "Epoch 48/100\n",
            "82/83 [============================>.] - ETA: 0s - loss: 0.0094 - categorical_accuracy: 0.9970\n",
            "Epoch 48: val_loss did not improve from 0.17834\n",
            "83/83 [==============================] - 4s 49ms/step - loss: 0.0093 - categorical_accuracy: 0.9970 - val_loss: 0.3893 - val_categorical_accuracy: 0.9759 - lr: 4.0960e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluates the trained model on a validation set and prints the test loss and accuracy.\n",
        "test_loss, test_score = model.evaluate(x_valid, y_valid, batch_size=24)\n",
        "print(\"Loss on test set: \", test_loss)\n",
        "print(\"Accuracy on test set: \", test_score)\n",
        "#2304 seconds 50 epochs\n",
        "#192 ms/step = average ms/step"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6LuOnSmM6I6",
        "outputId": "a1a312ad-53df-4c89-9732-c4021f588f0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 2s 44ms/step - loss: 0.2860 - categorical_accuracy: 0.9663\n",
            "Loss on test set:  0.2860070765018463\n",
            "Accuracy on test set:  0.966265082359314\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predictions using the trained model on the validation set (x_valid).\n",
        "#pred_y will contain the predicted outputs of the model for the validation set.\n",
        "\n",
        "pred_y = model.predict(x_valid, callbacks=callbacks_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLLVk1AJNB-C",
        "outputId": "de63c51d-ea6a-482f-dd47-b6a3f3a685d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 2s 89ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Original labels\n",
        "#checking the shapes of the original labels (orig_test_labels)\n",
        "#and the predicted labels (pred_y).\n",
        "orig_test_labels = np.argmax(y_valid, axis=-1)\n",
        "\n",
        "print(orig_test_labels.shape)\n",
        "print(pred_y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ePb5LRwNEvR",
        "outputId": "37fa294c-2c3d-4268-c1ce-9aafa97495aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(415,)\n",
            "(415, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(np.argmax(y_valid, axis = 1),np.argmax(pred_y, axis = 1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J41_E3w0NGkZ",
        "outputId": "657fc903-1180-4a66-fbce-345d4d699b1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.67      0.76        24\n",
            "           1       0.98      0.99      0.99       268\n",
            "           2       0.94      0.97      0.96       123\n",
            "\n",
            "    accuracy                           0.97       415\n",
            "   macro avg       0.94      0.88      0.90       415\n",
            "weighted avg       0.97      0.97      0.96       415\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the entire model (architecture and weights)\n",
        "model.save(r\"/content/drive/MyDrive/Sem4_Project /Pneumonia/lungcancer_resnet.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGBOh7D7Tr6V",
        "outputId": "1371d923-5f14-45e6-d55e-3fd9172a1cc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    }
  ]
}